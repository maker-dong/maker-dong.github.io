# HDFS相关知识

# HDFS概述

HDFS（Hadoop Distribute File System），Hadoop**分布式**文件系统，是 Hadoop 核心组件之一，作为最底层的分布式存储服务而存在。

## 分布式文件系统

将多台服务器的磁盘组合在一起，形成一个大的文件系统

## HDFS架构

- NameNode：管理整个文件系统，管理**元数据**信息
  - 元数据信息存储在NameNode中
- DataNode：存储数据
  - 分块存储，将一个文件切分成不同的文件块来存储数据。在HDFS中，将一个文件默认拆分成128M一个文件块
  - 为了防止文件出现丢失风险，对块进行备份处理，默认备份3块
- SecondaryNameNode：
  - 辅助管理NameNode的元数据信息

HDFS本质是一个软件，打通各个服务器的磁盘，数据存储在本地磁盘上

HDFS非常适合存储大型文件（TB、PB级别）

## HDFS三种机制

- **心跳机制**：DataNode与NameNode保持连接，如果在一定时间内没有和NameNode发送心跳连接，NameNode任务DataNode宕机了。
- **负载均衡机制**：如果某一台机子存储的数据已经快要满了，NameNode在处理的时候会尽量的不往该节点存储数据。
- **副本机制**：DataNode会定时报告自己节点中所有的块信息，NameNode会实时查看DataNode当中块的副本数量是否是足够的。如果不够，NameNode会请求DataNode添加新的副本；如果副本多了，会删除几个副本。

## HDFS的特性

1. 主从的架构：master/slave
2. 分块存储数据：在HDFS中每一块文件大小默认128M
3. 名称空间：每一个文件都有一个特定的路径指定文件的位置。每一个文件都会对应一份元数据信息（大约为120~150byte）
4. NameNode管理元数据
5. DataNode存储数据
6. 副本机制：默认3个
7. 一次写入多次读取：HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的修改。不允许用户对文件进行修改操作，每一次修改都要先修改NameNode中的元数据信息，再修改每一个副本中的信息。
8. HDFS的文件权限很弱：你说你是谁你就是谁，只能防止好人做错事，不能防止坏人做坏事。

## block块

HDFS将所有文件抽象为block块进行存储。

以block块的统一大小和形式进行存储，方便分布式文件系统对文件进行管理。

Hadoop1.x中一个block块默认64M，Hadoop2.x中一个block块默认128M

在`hdfs-sit.xml`中可以对block块大小进行设置。

```xml
<property>
	<name>dfs.block.size</name>
	<value>块大小 以字节为单位</value>//只写数值就可以 
</property>
```

**抽象为block块的好处**：

1. 存储上更加方便，不用在乎文件的类型，简化存储系统
2. 不论文件大小，只要大于128M就执行切割，进行分块存储
3. 可以针对于每一个块设置备份，提高数据容错能力和可用性

## HDFS的副本机制

为了保证block块的安全性，也就是数据的安全性，在Hadoop2.x当中，文件默认保存三个副本，我们可以更改副本数以提高数据的安全性。

在`hdfs-site.xml`当中修改以下配置属性，即可更改文件的副本数。

```xml
<property>
	<name>dfs.replication</name>
	<value>3</value>
</property>
```

**副本节点选择**

机架感知机制：

第一个副本在client所处的节点上。如果客户端在集群外，随机选一个。

第二个副本和第一个副本位于相同机架，随机节点。

第三个副本位于不同机架，随机节点。

![image-20230128103453805](http://image.coolcode.fun/images/202301281034961.png)

# HDFS工作流程

## 数据写入流程

1. client客户端请求NameNode，执行写入操作

2. NameNode接收到客户端请求后，验证是否有权限以及文件是否存在

3. 1. 如果没有权限或文件已存在，则抛异常
   2. 如果通过则通知client可以上传

4. 客户端开始对文件进行切分，默认128M

5. client再次请求NameNode，询问第一个block放置在哪些机子中

6. NameNode根据副本数量、机架感知原理以及网络拓扑关系，寻找更为适合的机器返回客户端机器列表

7. client连接列表中第一台的节点，第一台节点连接第二台节点，第二台连接第三台节点，建立pipeline管道

8. client开始往管道传输数据，数据以package(64kb)发送数据

9. 1. 当第一台接收到，将数据发送到第二台，第二台接收到，发送到第三台
   2. 每一次发送完成以后，都会有一个应答队列

10. 当每一个DataNode接收到数据后，都给ack的应答响应，告知已经接收完毕了

11. 当第一块发送完成后，再次请求NameNode，询问第二个block应该放置在哪些机子中

12. 1. 再次第5步，以此类推，直至将数据全部保存到DataNode中

![image-20230128103603449](http://image.coolcode.fun/images/202301281036587.png)

## 数据读取流程

1. 客户端发送请求NameNode，询问是否可以读取对应的文件

2. NameNode接收到请求后，验证用户的权限和是否存在文件

3. 1. 如果验证失败，直接抛异常
   2. 如果验证通过，返回部分或全部的block的地址列表

4. 客户端根据NameNode给出的block地址，并发的访问对应的地址，获取block数据

5. 如果NamoNode返回的是一部分的列表，再次请求NameNode，获取下一批的block的地址

6. 最终将所有的block的文件块拼接在一起，形成完整的文件